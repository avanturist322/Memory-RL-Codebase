[2024-06-05 20:46:45,443][jax._src.xla_bridge][INFO] - Unable to initialize backend 'cuda': 
[2024-06-05 20:46:45,443][jax._src.xla_bridge][INFO] - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
[2024-06-05 20:46:45,444][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2024-06-05 20:46:45,506][__main__][INFO] - Starting Job for Config:
tags: null
project_name: T Maze
seed: 1
steps: 5000000
log_interval: 10000
eval_interval: null
save_interval: null
task:
  task: tmazev2
  corridor_len: 120
  num_distractors: 6
  max_steps: null
  max_episode_steps: 1000
trainer:
  agent: a2c
  rollout_len: 256
  num_envs: 8
  seq_model:
    name: relit
    n_layers: 4
    d_model: 128
    d_head: 64
    d_ffc: 128
    n_heads: 4
    update_rule: projected_sigmoid
    flow: gtrxl
    kernel:
      name: pp_relu
      nu: 2
    reset_hidden_on_terminate: true
  d_actor: 128
  d_critic: 128
  gamma: 0.99
  lamb: 0.95
  entropy_coef: 0.001
  value_coef: 0.5
  max_grad_norm: 0.5
  optimizer:
    learning_rate: 0.0001
  arg_max: false
use_wandb: true

[2024-06-05 20:46:45,507][__main__][INFO] - Available Backends:[CpuDevice(id=0)]
[2024-06-05 20:46:49,277][src.trainers.trainers_control][INFO] - Using async env
[2024-06-05 20:46:50,154][src.trainers.trainers_control][INFO] - Observation space: Box(0.0, 1.0, (16,), float32)
[2024-06-05 20:46:50,154][src.trainers.trainers_control][INFO] - Action space: Discrete(4)
[2024-06-05 20:46:58,803][src.agents.base_agent][INFO] - Total Number of params: 1826405
[2024-06-05 20:46:58,804][src.agents.base_agent][INFO] - Number of params in Seq Model: 1792736
[2024-06-05 20:49:02,819][__main__][INFO] - Seed: 1 Steps: 10240 Metrics: {'step': 10240, 'sps': 164.92566894061642, 'loss': nan, 'critic_loss': nan, 'actor_loss': nan, 'entropy_loss': nan, 'mean_reward': -0.10240001231431961, 'return_per_episode': -9.01005, 'success': 0.0, 'new_cue': 0.125, 'episode_length': 1000.0, 'reward_per_episode': -100.00000000000001}
